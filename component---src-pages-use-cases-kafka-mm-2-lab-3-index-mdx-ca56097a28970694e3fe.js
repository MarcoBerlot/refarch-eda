(window.webpackJsonp=window.webpackJsonp||[]).push([[83,95],{"0/4p":function(e,t,a){"use strict";a.r(t),a.d(t,"_frontmatter",(function(){return c})),a.d(t,"default",(function(){return m}));var r=a("wx14"),n=a("zLVn"),o=(a("q1tI"),a("7ljp")),s=a("013z"),c=(a("qKvR"),{}),i=function(e){return function(t){return console.warn("Component '"+e+"' was not imported, exported, or provided by MDXProvider as global scope"),Object(o.b)("div",t)}},l=i("AnchorLinks"),p=i("AnchorLink"),b={_frontmatter:c},d=s.a;function m(e){var t=e.components,a=Object(n.a)(e,["components"]);return Object(o.b)(d,Object(r.a)({},b,a,{components:t,mdxType:"MDXLayout"}),Object(o.b)(l,{mdxType:"AnchorLinks"},Object(o.b)(p,{mdxType:"AnchorLink"},"Overview"),Object(o.b)(p,{mdxType:"AnchorLink"},"Pre-requisites"),Object(o.b)(p,{mdxType:"AnchorLink"},"Start Mirror Maker 2"),Object(o.b)(p,{mdxType:"AnchorLink"},"Start Producer to source cluster"),Object(o.b)(p,{mdxType:"AnchorLink"},"Consuming records on source"),Object(o.b)(p,{mdxType:"AnchorLink"},"Failover to target")),Object(o.b)("p",null,"Updated 01/08/2021"),Object(o.b)("h2",null,"Overview"),Object(o.b)("p",null,"This lab presents how to leverage Mirror Maker 2 between two on-premise Kafka clusters running on OpenShift, one having no consumer and producer connected to it: it is in passive mode. The cluster is still getting replicated data. The lab goes up to the failover and reconnect consumers to the newly promoted active cluster."),Object(o.b)("p",null," ",Object(o.b)("span",Object(r.a)({parentName:"p"},{className:"gatsby-resp-image-wrapper",style:{position:"relative",display:"block",marginLeft:"auto",marginRight:"auto",maxWidth:"1152px"}}),"\n      ",Object(o.b)("span",Object(r.a)({parentName:"span"},{className:"gatsby-resp-image-background-image",style:{paddingBottom:"37.5%",position:"relative",bottom:"0",left:"0",backgroundImage:"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAABYlAAAWJQFJUiTwAAABx0lEQVQoz02Sz2oTURTG807ic/gSPkFWblwI4saFCxdqqUUqZKOgC5GSWKzFjZSCFkwJJkbaJk3nTyaTmblz/839eTIq9cI3B84597vfd850nAkED1UFSfIXcaCuA96Bkbq1AgNOohdky0AcBRaL0Pb+yxsd6KS5IUpyzqbn/Po5I0sKqrVGV5osXWNqJ42wSkuqoiZOFefziuVSowpLXRqUMqwKjS01HR/gdDTi2dZTnu9sMx5P2BxrHOVaYWtLWYWWTARzdOnpjzWjhYLgCKFB+4ZMHrZC3IHmz2WluYgTilLhGy9ocMZS5VrU2JYwmWd8eHlCf/crk+EcpWsZSyPE8lIQ60La6b6YcOvhkK2Ps1bZ9nTAjf0uNz916UdfRCpoazkdenZ3Cj6/Oebg1TcmPy6Fx+JF90qX5LZE12L57dGCR6/n3H+8bgn3Zyf0Lgbc3Tug9y5pc9naU2RGrPPfCUzPLPcOe9wePODO4RPSfLWx7Npynm6+/rp/s4hIYuNQtQi9ioXDEKyj0bbt3XtvOP6+ICpmJHksZbFcLBWqcjIvJ5v1qFKWUBhqGbCXGaqqkV8HiUEsXaNWoZ3bRkMj/F6gJP8b0KFX4G3fxqwAAAAASUVORK5CYII=')",backgroundSize:"cover",display:"block"}})),"\n  ",Object(o.b)("img",Object(r.a)({parentName:"span"},{className:"gatsby-resp-image-image",alt:"1",title:"1",src:"/refarch-eda/static/bdd334cfb18724acc6128d67fb312885/3cbba/mm2-lab3.png",srcSet:["/refarch-eda/static/bdd334cfb18724acc6128d67fb312885/7fc1e/mm2-lab3.png 288w","/refarch-eda/static/bdd334cfb18724acc6128d67fb312885/a5df1/mm2-lab3.png 576w","/refarch-eda/static/bdd334cfb18724acc6128d67fb312885/3cbba/mm2-lab3.png 1152w","/refarch-eda/static/bdd334cfb18724acc6128d67fb312885/3933f/mm2-lab3.png 1636w"],sizes:"(max-width: 1152px) 100vw, 1152px",style:{width:"100%",height:"100%",margin:"0",verticalAlign:"middle",position:"absolute",top:"0",left:"0"},loading:"lazy"})),"\n    ")),Object(o.b)("ol",null,Object(o.b)("li",{parentName:"ol"},"Mirror Maker 2 runs on OpenShift as pod in the same namespace as Event Streams on the target cluster"),Object(o.b)("li",{parentName:"ol"},"A producer in python to send records to ",Object(o.b)("inlineCode",{parentName:"li"},"products")," topic, will run locally or could be deployed on OpenShift as a ",Object(o.b)("strong",{parentName:"li"},"job")),Object(o.b)("li",{parentName:"ol"},"A consumer, also in python is consuming n records, in auto commit, so there will be a consumer lag before the failover."),Object(o.b)("li",{parentName:"ol"},"For the failover, we will stop the producer. We could stop event streams, but the most important is that there is no more records coming from the source cluster to the target cluster via mirroring. The goal not is to connect the consumer to the target cluster and then continue from where the consumer on the source cluster has stopped. If those consumer was writing to a database then the DB in the passive environment will receive the new records. If the database is in a 3nd environment like a managed service in the cloud with HA, then new records will be added to the original one. If the database server was also doing replication between active and passive environments then it may be possible to get a gap in the data, depending of the DB replication settings. ")),Object(o.b)("p",null,"In the figure above, the offset numbering does not have to match with source. This is where mirror maker 2 is keeping offset metadata on its own topics. The commit offsets for each consumer groups is also saved, so consumers restarting on the target cluster will continue for the matching offset corresponding to the last read committed offset."),Object(o.b)("h2",null,"Pre-requisites"),Object(o.b)("ul",null,Object(o.b)("li",{parentName:"ul"},Object(o.b)("p",{parentName:"li"},"We assume, you have access to two Kafka Clusters deployed on OpenShift. We use two Event Streams instances on the same OpensShift cluster for this lab.  ")),Object(o.b)("li",{parentName:"ul"},Object(o.b)("p",{parentName:"li"},"Login to the OpenShift cluster using the console and get the API token"),Object(o.b)("pre",{parentName:"li"},Object(o.b)("code",Object(r.a)({parentName:"pre"},{className:"language-shell"}),"oc login --token=L0.... --server=https://api.eda-solutions.gse-ocp.net:6443\n"))),Object(o.b)("li",{parentName:"ul"},Object(o.b)("p",{parentName:"li"},"If not done from lab 1, clone the github to get access to the Mirror Maker 2 manifests we are using:"),Object(o.b)("pre",{parentName:"li"},Object(o.b)("code",Object(r.a)({parentName:"pre"},{className:"language-shell"}),"git clone https://github.com/ibm-cloud-architecture/refarch-eda-tools\n"))),Object(o.b)("li",{parentName:"ul"},Object(o.b)("p",{parentName:"li"},"Create the ",Object(o.b)("inlineCode",{parentName:"p"},"products")," topic on the source cluster.")),Object(o.b)("li",{parentName:"ul"},Object(o.b)("p",{parentName:"li"},"Under the labs/MirrorMaker2/active-passive folder, rename the ",Object(o.b)("inlineCode",{parentName:"p"},".env-tmpl")," file to ",Object(o.b)("inlineCode",{parentName:"p"},".env"),". ")),Object(o.b)("li",{parentName:"ul"},Object(o.b)("p",{parentName:"li"},"Get the source and target bootstrap server external URLs for the producer and consumer code using ",Object(o.b)("inlineCode",{parentName:"p"},"oc get routes | grep bootstrap"),". We will use to demonstrate the offset management and consumer reconnection then modify the addresses in the ",Object(o.b)("inlineCode",{parentName:"p"},".env")," file"),Object(o.b)("pre",{parentName:"li"},Object(o.b)("code",Object(r.a)({parentName:"pre"},{className:"language-properties"}),"ES_SRC_BROKERS=light-es-kafka-bootstrap-eventstreams.gse-eda-2020-10-3-0143c5dd31acd8e030a1d6e0ab1380e3-0000.us-east.containers.appdomain.cloud:443\nES_TGT_BROKERS=gse-eda-dev-kafka-bootstrap-eventstreams.gse-eda-2020-10-3-0143c5dd31acd8e030a1d6e0ab1380e3-0000.us-east.containers.appdomain.cloud:443\n"))),Object(o.b)("li",{parentName:"ul"},Object(o.b)("p",{parentName:"li"},"Get SCRAM users for both cluster and set their names in the ",Object(o.b)("inlineCode",{parentName:"p"},".env")," file"),Object(o.b)("pre",{parentName:"li"},Object(o.b)("code",Object(r.a)({parentName:"pre"},{className:"language-properties"}),"ES_SRC_USER=starter\nES_TGT_USER=user2\n"))),Object(o.b)("li",{parentName:"ul"},Object(o.b)("p",{parentName:"li"},"Get pem certificates from both clusters using each admin console web apps, or the CLI:"),Object(o.b)("pre",{parentName:"li"},Object(o.b)("code",Object(r.a)({parentName:"pre"},{className:"language-shell"}),"cloudctl es init\n# select one of the cluster, then...\ncloudctl es certificates --format pem\n# rename the es-cert.pem to \nmv es-cert.pem es-src-cert.pem\n# Get for the second cluster\ncloudctl es init\ncloudctl es certificates --format pem\nmv es-cert.pem es-tgt-cert.pem\n"))),Object(o.b)("li",{parentName:"ul"},Object(o.b)("p",{parentName:"li"},"Verify the Event Streams on OpenShift service end point URLs. Those URLs will be used to configure Mirror Maker 2. "),Object(o.b)("pre",{parentName:"li"},Object(o.b)("code",Object(r.a)({parentName:"pre"},{className:"language-shell"}),"# Use the bootstrap internal URL\noc get svc | grep bootstrap\n# Get both internal URLs\nlight-es-kafka-bootstrap.evenstreams.svc:9092\ngse-eda-dev-kafka-bootstrap.evenstreams.svc:9092\n")))),Object(o.b)("h2",null,"Start Mirror Maker 2"),Object(o.b)("p",null,"In this lab, Mirror Maker 2 will run on the same cluster as Event Streams within the same namespace (e.g. eventstreams). "),Object(o.b)("ul",null,Object(o.b)("li",{parentName:"ul"},Object(o.b)("p",{parentName:"li"},"Define source and target cluster properties in a Mirror Maker 2 ",Object(o.b)("inlineCode",{parentName:"p"},"es-to-es.yml")," descriptor file. We strongly recommend to study the schema definition of this ",Object(o.b)("a",Object(r.a)({parentName:"p"},{href:"https://github.com/strimzi/strimzi-kafka-operator/blob/2d35bfcd99295bef8ee98de9d8b3c86cb33e5842/install/cluster-operator/048-Crd-kafkamirrormaker2.yaml#L648-L663"}),"custom resource from this page"),". "),Object(o.b)("p",{parentName:"li"}," Here are some important parameters you need to consider: The namespace needs to match the event streams project, and the annotations the product version and ID. The connectCluster needs to match the alias of the target cluster. The alias ",Object(o.b)("inlineCode",{parentName:"p"},"es-tgt")," represents the kafka cluster Mirror Maker 2 needs to connect to:"),Object(o.b)("pre",{parentName:"li"},Object(o.b)("code",Object(r.a)({parentName:"pre"},{className:"language-yaml"}),'apiVersion: eventstreams.ibm.com/v1alpha1\nkind: KafkaMirrorMaker2\nmetadata:\n  name: mm2\n  namespace: eventstreams\nspec:\n  template:\n    pod:\n      metadata:\n        annotations:\n          eventstreams.production.type: CloudPakForIntegrationNonProduction\n          productCloudpakRatio: "2:1"\n          productChargedContainers: mm2-mirrormaker2\n          productVersion: 10.1.0\n          productID: 2a79e49111f44ec3acd89608e56138f5\n          cloudpakName: IBM Cloud Pak for Integration\n          cloudpakId: c8b82d189e7545f0892db9ef2731b90d\n          productName: IBM Event Streams for Non Production\n          cloudpakVersion: 2020.3.1\n          productMetric: VIRTUAL_PROCESSOR_CORE\n  version: 2.6.0\n  replicas: 1\n  connectCluster: "es-tgt"\n')),Object(o.b)("p",{parentName:"li"}," The version matches the Kafka version we use. The number of replicas can be set to 1 to start with or use the default of 3. The ",Object(o.b)("inlineCode",{parentName:"p"},"eventstreams.production.type")," is needed for Event Streams."),Object(o.b)("p",{parentName:"li"}," Then the yaml defines the connection configuration for each clusters:"),Object(o.b)("pre",{parentName:"li"},Object(o.b)("code",Object(r.a)({parentName:"pre"},{className:"language-yaml"}),'clusters:\n  - alias: "es-src"\n    bootstrapServers: \n    config:\n      config.storage.replication.factor: 3\n      offset.storage.replication.factor: 3\n      status.storage.replication.factor: 3\n    tls: {}\n')),Object(o.b)("p",{parentName:"li"}," For Event Streams on premise running within OpenShift, the connection uses TLS, certificates and SCRAM credentials. As we run in a separate namespace the URL is the ‘external’ one."),Object(o.b)("pre",{parentName:"li"},Object(o.b)("code",Object(r.a)({parentName:"pre"},{className:"language-yaml"}),'- alias: "es-src"\n    bootstrapServers: light-es-kafka-bootstrap.integration.svc:9093\n    config:\n      ssl.endpoint.identification.algorithm: https\n    tls: \n      trustedCertificates:\n        - secretName: light-es-cluster-ca-cert\n          certificate: ca.crt\n    authentication:\n      type: tls\n      certificateAndKey:\n        certificate: user.crt\n        key: user.key\n        secretName: es-tls-user\n          \n')),Object(o.b)("p",{parentName:"li"},"Finally the ",Object(o.b)("inlineCode",{parentName:"p"},"connectCluster")," attribute defines the cluster alias used by MirrorMaker2 to define its hidden topics, it must match the target cluster of the replication in the list at ",Object(o.b)("inlineCode",{parentName:"p"},"spec.clusters"),"."),Object(o.b)("pre",{parentName:"li"},Object(o.b)("code",Object(r.a)({parentName:"pre"},{className:"language-shell"}),"# under active-passive folder\noc apply -f es-to-es.yml\n"))),Object(o.b)("li",{parentName:"ul"},Object(o.b)("p",{parentName:"li"},"Verify the characteristics of the Mirror Maker 2 instance using the CLI"),Object(o.b)("pre",{parentName:"li"},Object(o.b)("code",Object(r.a)({parentName:"pre"},{className:"language-shell"}),"oc describe kafkamirrormaker2 mm2\n"))),Object(o.b)("li",{parentName:"ul"},Object(o.b)("p",{parentName:"li"},"See the logs:"),Object(o.b)("pre",{parentName:"li"},Object(o.b)("code",Object(r.a)({parentName:"pre"},{className:"language-shell"}),"oc get pods | grep mm2\noc logs mm2-mirrormaker2-...\n")))),Object(o.b)("h2",null,"Start Producer to source cluster"),Object(o.b)("p",null,"As seen in lab 1, we will use the same python script to create products records. This time the script is producing product records to the ",Object(o.b)("inlineCode",{parentName:"p"},"products")," topic. "),Object(o.b)("p",null," Now send 100 records:"),Object(o.b)("pre",null,Object(o.b)("code",Object(r.a)({parentName:"pre"},{className:"language-shell"}),"./sendProductRecords.sh --random 100\n")),Object(o.b)("p",null,"The trace looks like:"),Object(o.b)("pre",null,Object(o.b)("code",Object(r.a)({parentName:"pre"},{}),"--- This is the configuration for the producer: ---\n[KafkaProducer] - {'bootstrap.servers': 'light-es-kafka-bootstrap-eventstreams.gse-eda-2020-10-3-0143c5dd31acd8e030a1d6e0ab1380e3-0000.us-east.containers.appdomain.cloud:443', 'group.id': 'ProductsProducer', 'delivery.timeout.ms': 15000, 'request.timeout.ms': 15000, 'security.protocol': 'SASL_SSL', 'sasl.mechanisms': 'SCRAM-SHA-512', 'sasl.username': 'starter', 'sasl.password': 'd8zsUzhK9qUZ', 'ssl.ca.location': '/home/active-passive/es-cert.pem'}\n---------------------------------------------------\n{'product_id': 'T1', 'description': 'Product 1', 'target_temperature': 6.321923853806639, 'target_humidity_level': 0.4, 'content_type': 1}\n{'product_id': 'T2', 'description': 'Product 2', 'target_temperature': 4.991504310455889, 'target_humidity_level': 0.4, 'content_type': 1}\n{'product_id': 'T3', 'description': 'Product 3', 'target_temperature': 4.491634291119919, 'target_humidity_level': 0.4, 'content_type': 1}\n{'product_id': 'T4', 'description': 'Product 4', 'target_temperature': 2.4855241432802613, 'target_humidity_level': 0.4, 'content_type': 1}\n{'product_id': 'T5', 'description': 'Product 5', 'target_temperature': 4.286428275499635, 'target_humidity_level': 0.4, 'content_type': 1}\n{'product_id': 'T6', 'description': 'Product 6', 'target_temperature': 1.6025770613167736, 'target_humidity_level': 0.4, 'content_type': 1}\n")),Object(o.b)("ul",null,Object(o.b)("li",{parentName:"ul"},"Going to the Event Streams Console we can see the produced messages in the ",Object(o.b)("inlineCode",{parentName:"li"},"products")," topic.")),Object(o.b)("span",{className:"gatsby-resp-image-wrapper",style:{position:"relative",display:"block",marginLeft:"auto",marginRight:"auto",maxWidth:"1152px"}},"\n      ",Object(o.b)("span",Object(r.a)({parentName:"span"},{className:"gatsby-resp-image-background-image",style:{paddingBottom:"44.09722222222222%",position:"relative",bottom:"0",left:"0",backgroundImage:"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAAsSAAALEgHS3X78AAABSUlEQVQoz61S20rEMBDtt7l/s7h2t2DVB9/WfxBB3/wDf0LBG4J4eRGk2rpbu22SNmmTHjNZW1wRBDFwyMw0OXPOpN7aYIBwawfD4RDj8Ri+7/8ZE3vfm073QEtrjf9Y3ma4DSkl0vQdz1ECzgVqyVBXzHaRME0FUws0tULTNK7xT1C1hlQa3mhjgjhOEL28QvIUJ6cFgiOO3WOO4JBhdFBgfX+By0eB1pJr0zolbdv2qpbxEl4Yhq6Y5wWqSuApSnF+G+P6/g1nNxEu7hJcPcwxzwTKUqCybjqysiytI97ntHtBEHwS5iiKArqWXV9nWSsBGGvX1hnjMMb0BJ1dyjusEDLGrEo7M/uhsQcpXyxyCFG6OuHXR/lOSDZo+KREKeVIKKeHIwdUo5j2Lv6KFUKaB10iEDFBCOFI6XCWZfZvSFcwm816MYQPLmiMWJbfv4IAAAAASUVORK5CYII=')",backgroundSize:"cover",display:"block"}})),"\n  ",Object(o.b)("img",Object(r.a)({parentName:"span"},{className:"gatsby-resp-image-image",alt:"Products topic",title:"Products topic",src:"/refarch-eda/static/e11d46b6c36c0dfb1d2e62db3873e185/3cbba/es-products-topic.png",srcSet:["/refarch-eda/static/e11d46b6c36c0dfb1d2e62db3873e185/7fc1e/es-products-topic.png 288w","/refarch-eda/static/e11d46b6c36c0dfb1d2e62db3873e185/a5df1/es-products-topic.png 576w","/refarch-eda/static/e11d46b6c36c0dfb1d2e62db3873e185/3cbba/es-products-topic.png 1152w","/refarch-eda/static/e11d46b6c36c0dfb1d2e62db3873e185/1d1d1/es-products-topic.png 1565w"],sizes:"(max-width: 1152px) 100vw, 1152px",style:{width:"100%",height:"100%",margin:"0",verticalAlign:"middle",position:"absolute",top:"0",left:"0"},loading:"lazy"})),"\n    "),Object(o.b)("h2",null,"Start the Consumer to source cluster"),Object(o.b)("p",null,"To simulate the offset mapping between source and target, we will use a python consumer and read only n records."),Object(o.b)("pre",null,Object(o.b)("code",Object(r.a)({parentName:"pre"},{className:"language-shell"})," ./receiveProductSrc.sh 20\n")),Object(o.b)("p",null,"The trace may look like:"),Object(o.b)("pre",null,Object(o.b)("code",Object(r.a)({parentName:"pre"},{}),'--------- Start Consuming products --------------\n[KafkaConsumer] - This is the configuration for the consumer:\n[KafkaConsumer] - -------------------------------------------\n[KafkaConsumer] - Bootstrap Server:      light-es-kafka-bootstrap-eventstreams.gse-eda-2020-10-3-0143c5dd31acd8e030a1d6e0ab1380e3-0000.us-east.containers.appdomain.cloud:443\n[KafkaConsumer] - Topic:                 products\n[KafkaConsumer] - Topic timeout:         10\n[KafkaConsumer] - Security Protocol:     SASL_SSL\n[KafkaConsumer] - SASL Mechanism:        SCRAM-SHA-512\n[KafkaConsumer] - SASL Username:         starter\n[KafkaConsumer] - SASL Password:         d*****Z\n[KafkaConsumer] - SSL CA Location:       /home/active-passive/es-cert.pem\n[KafkaConsumer] - Offset Reset:          earliest\n[KafkaConsumer] - Autocommit:            True\n[KafkaConsumer] - -------------------------------------------\n[KafkaConsumer] - Next Message consumed from products partition: [0] at offset: 0\n    key: P01\n    value: {"product_id": "P01", "description": "Carrots", "target_temperature": 4, "target_humidity_level": 0.4, "content_type": 1}\n[KafkaConsumer] - Next Message consumed from products partition: [0] at offset: 1\n    key: P02\n    value: {"product_id": "P02", "description": "Banana", "target_temperature": 6, "target_humidity_level": 0.6, "content_type": 2}\n[KafkaConsumer] - Next Message consumed from products partition: [0] at offset: 2\n    key: P03\n    value: {"product_id": "P03", "description": "Salad", "target_temperature": 4, "target_humidity_level": 0.4, "content_type": 1}\n[KafkaConsumer] - Next Message consumed from products partition: [0] at offset: 3\n    key: P04\n    value: {"product_id": "P04", "description": "Avocado", "target_temperature": 6, "target_humidity_level": 0.4, "content_type": 1}\n[KafkaConsumer] - Next Message consumed from products partition: [0] at offset: 4\n    key: P05\n    value: {"product_id": "P05", "description": "Tomato", "target_temperature": 4, "target_humidity_level": 0.4, "content_type": 2}\n[KafkaConsumer] - Next Message consumed from products partition: [0] at offset: 5\n    key: T1\n    value: {"product_id": "T1", "description": "Product 1", "target_temperature": 6.321923853806639, "target_humidity_level": 0.4, "content_type": 1}\n[KafkaConsumer] - Next Message consumed from products partition: [0] at offset: 6\n\n')),Object(o.b)("p",null,"The python code is ",Object(o.b)("a",Object(r.a)({parentName:"p"},{href:"https://github.com/ibm-cloud-architecture/refarch-eda-tools/blob/master/labs/mirror-maker2/consumer/ProductConsumer.py"}),"ProductConsumer.py"),"."),Object(o.b)("p",null,"If we go to Event Streams consumer group monitoring user interface we can see the consumer only got 20 messages and so there is an offset lag, as illustrated in figure below:"),Object(o.b)("p",null," ",Object(o.b)("span",Object(r.a)({parentName:"p"},{className:"gatsby-resp-image-wrapper",style:{position:"relative",display:"block",marginLeft:"auto",marginRight:"auto",maxWidth:"865px"}}),"\n      ",Object(o.b)("span",Object(r.a)({parentName:"span"},{className:"gatsby-resp-image-background-image",style:{paddingBottom:"37.15277777777778%",position:"relative",bottom:"0",left:"0",backgroundImage:"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAAsSAAALEgHS3X78AAAA20lEQVQoz5VR2YqEQAzs//85LzzQB8VbvB5U8K6daiYy7LILGyhSla6kO7Tatg1932vM8wzqdV0hcd+3xm8hZ/dx4Hr1qWVZkCSJRlmWKIpC43gZHvN76J94X6D4GuK6Luz7DtEcyFcPw4D/hGIjhzFzIDnBW2X98zwf0PfJv2uV5zlM00SapgjDELZtw3VdWJaFOI71+qxTB0EA+n3fh2EYiKIIWZbBcRx4nqe9imu1batXI++67oGs3DSN9oiuqurRRF3XOo/jCMWf5ccwCxdI7bNOPk3TD4/wL8w/GctoXXp5AAAAAElFTkSuQmCC')",backgroundSize:"cover",display:"block"}})),"\n  ",Object(o.b)("img",Object(r.a)({parentName:"span"},{className:"gatsby-resp-image-image",alt:"Consumer lag",title:"Consumer lag",src:"/refarch-eda/static/edb1de0773ab01fd9e990cc75d06a22f/00ec4/consumer-lag.png",srcSet:["/refarch-eda/static/edb1de0773ab01fd9e990cc75d06a22f/7fc1e/consumer-lag.png 288w","/refarch-eda/static/edb1de0773ab01fd9e990cc75d06a22f/a5df1/consumer-lag.png 576w","/refarch-eda/static/edb1de0773ab01fd9e990cc75d06a22f/00ec4/consumer-lag.png 865w"],sizes:"(max-width: 865px) 100vw, 865px",style:{width:"100%",height:"100%",margin:"0",verticalAlign:"middle",position:"absolute",top:"0",left:"0"},loading:"lazy"})),"\n    ")),Object(o.b)("h2",null,"Failover to target"),Object(o.b)("p",null,"At this stage, the producer code is not running anymore, Mirror Maker 2 has replicated the data to the target topic named: ",Object(o.b)("inlineCode",{parentName:"p"},"es-src.products"),", the consumer has not read all the messages from source cluster. This simulate a crash on source cluster. So let now connect the consumer to the target cluster and continue to process the records. For that the consumer needs to get the offset mapping using the ",Object(o.b)("a",Object(r.a)({parentName:"p"},{href:"https://downloads.apache.org/kafka/2.5.0/javadoc/org/apache/kafka/connect/mirror/RemoteClusterUtils.html"}),"RemoteClusterUtils class")," to translate the consumer group offset from the source cluster to the corresponding offset for the target cluster. "))}m.isMDXComponent=!0},"013z":function(e,t,a){"use strict";var r=a("q1tI"),n=a.n(r),o=a("NmYn"),s=a.n(o),c=a("Wbzz"),i=a("Xrax"),l=a("k4MR"),p=a("TSYQ"),b=a.n(p),d=a("QH2O"),m=a("qKvR"),u=function(e){var t,a=e.title,r=e.tabs,n=void 0===r?[]:r;return Object(m.b)("div",{className:b()(d.pageHeader,(t={},t[d.withTabs]=n.length,t))},Object(m.b)("div",{className:"bx--grid"},Object(m.b)("div",{className:"bx--row"},Object(m.b)("div",{className:"bx--col-lg-12"},Object(m.b)("h1",{id:"page-title",className:d.text},a)))))},h=a("BAC9"),g=function(e){var t=e.relativePagePath,a=e.repository,r=Object(c.useStaticQuery)("1364590287").site.siteMetadata.repository,n=a||r,o=n.baseUrl,s=n.subDirectory,i=o+"/edit/"+n.branch+s+"/src/pages"+t;return o?Object(m.b)("div",{className:"bx--row "+h.row},Object(m.b)("div",{className:"bx--col"},Object(m.b)("a",{className:h.link,href:i},"Edit this page on GitHub"))):null},f=a("FCXl"),O=a("dI71"),j=a("I8xM"),v=function(e){function t(){return e.apply(this,arguments)||this}return Object(O.a)(t,e),t.prototype.render=function(){var e=this.props,t=e.tabs,a=e.slug,r=a.split("/").filter(Boolean).slice(-1)[0],n=t.map((function(e){var t,n=s()(e,{lower:!0,strict:!0}),o=n===r,i=new RegExp(r+"/?(#.*)?$"),l=a.replace(i,n);return Object(m.b)("li",{key:e,className:b()((t={},t[j.selectedItem]=o,t),j.listItem)},Object(m.b)(c.Link,{className:j.link,to:""+l},e))}));return Object(m.b)("div",{className:j.tabsContainer},Object(m.b)("div",{className:"bx--grid"},Object(m.b)("div",{className:"bx--row"},Object(m.b)("div",{className:"bx--col-lg-12 bx--col-no-gutter"},Object(m.b)("nav",null,Object(m.b)("ul",{className:j.list},n))))))},t}(n.a.Component),N=a("MjG9");t.a=function(e){var t=e.pageContext,a=e.children,r=e.location,n=e.Title,o=t.frontmatter,p=void 0===o?{}:o,b=t.relativePagePath,d=t.titleType,h=p.tabs,O=p.title,j=p.theme,k=p.description,A=p.keywords,y=Object(c.useStaticQuery)("2456312558").site.pathPrefix,w=y?r.pathname.replace(y,""):r.pathname,C=h?w.split("/").filter(Boolean).slice(-1)[0]||s()(h[0],{lower:!0}):"";return Object(m.b)(l.a,{tabs:h,homepage:!1,theme:j,pageTitle:O,pageDescription:k,pageKeywords:A,titleType:d},Object(m.b)(u,{title:n?Object(m.b)(n,null):O,label:"label",tabs:h}),h&&Object(m.b)(v,{slug:w,tabs:h,currentTab:C}),Object(m.b)(N.a,{padded:!0},a,Object(m.b)(g,{relativePagePath:b})),Object(m.b)(f.a,{pageContext:t,location:r,slug:w,tabs:h,currentTab:C}),Object(m.b)(i.a,null))}},BAC9:function(e,t,a){e.exports={bxTextTruncateEnd:"EditLink-module--bx--text-truncate--end--2pqje",bxTextTruncateFront:"EditLink-module--bx--text-truncate--front--3_lIE",link:"EditLink-module--link--1qzW3",row:"EditLink-module--row--1B9Gk"}},I8xM:function(e,t,a){e.exports={bxTextTruncateEnd:"PageTabs-module--bx--text-truncate--end--267NA",bxTextTruncateFront:"PageTabs-module--bx--text-truncate--front--3xEQF",tabsContainer:"PageTabs-module--tabs-container--8N4k0",list:"PageTabs-module--list--3eFQc",listItem:"PageTabs-module--list-item--nUmtD",link:"PageTabs-module--link--1mDJ1",selectedItem:"PageTabs-module--selected-item--YPVr3"}},QH2O:function(e,t,a){e.exports={bxTextTruncateEnd:"PageHeader-module--bx--text-truncate--end--mZWeX",bxTextTruncateFront:"PageHeader-module--bx--text-truncate--front--3zvrI",pageHeader:"PageHeader-module--page-header--3hIan",withTabs:"PageHeader-module--with-tabs--3nKxA",text:"PageHeader-module--text--o9LFq"}}}]);
//# sourceMappingURL=component---src-pages-use-cases-kafka-mm-2-lab-3-index-mdx-ca56097a28970694e3fe.js.map