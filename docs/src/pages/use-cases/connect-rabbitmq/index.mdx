---
title: Kafka Connect to RabbitMQ Source Connector
description: Apache Kafka to RabbitMQ Source Connector usecase
---

<InlineNotification kind="warning">
<strong>Updated 10/23/2020</strong>
</InlineNotification>

<AnchorLinks>
<AnchorLink>Just run it!</AnchorLink>
<AnchorLink>Deploy on OpenShift</AnchorLink>
</AnchorLinks>

This hands-on lab demonstrates how to use IBM RabbitMQ source connector to inject message to Event Streams On Premise. 
We are using the [IBM messaging github: source Kafka connector for RabbitMQ](https://github.com/ibm-messaging/kafka-connect-rabbitmq-source) open sourced component. The configuration for this connector is also done using Json config file, with a POST to the Kafka connectors URL.

The following diagram illustrates the component of this demo / lab:

![0](./images/comp-view.png)

The configurations used in this use case are in the `refarch-eda-tools` repository that you should clone:

```shell
git clone https://github.com/ibm-cloud-architecture/refarch-eda-tools
```

## Just run it!

For demonstration purpose, we have defined a docker compose file and a set of images ready to be used. So it will be eaiery to demonstrate the scenario of sending messages to Rabbit MQ `items` queue, have a Kafka connector configured and a simple Kafka consumer which consumes JSon doc from `items` topic. 

To send message to RabbitMQ, we have implemented a simple store simulator, to send item sale messages for a set of stores. The code is under [eda-store-simulator](https://github.com/ibm-cloud-architecture/refarch-eda-store-simulator) repository and we have also uploaded the image [into dockerhub ibmcase/eda-store-simulator](https://hub.docker.com/repository/docker/ibmcase/eda-store-simulator).

To quickly start a local demonstration environment, the [github repository for this lab](https://github.com/ibm-cloud-architecture/refarch-eda-tools) includes a [docker compose file](https://github.com/ibm-cloud-architecture/refarch-eda-tools/tree/master/labs/rabbitmq-source-lab/docker-compose.yaml) under the `labs/rabbitmq-source-lab` folder.

```shell
git clone https://github.com/ibm-cloud-architecture/refarch-eda-tools
cd refarch-eda-tools/labs/rabbitmq-source-lab
docker-compose up &
docker ps 

IMAGE                              COMMAND                   PORT                  
ibmcase/kconnect:v1.0.0            "./bin/connect-distr…"    0.0.0.0:8083->8083/  
strimzi/kafka:latest-kafka-2.6.0   "sh -c 'bin/kafka-se…"    0.0.0.0:9092->9092/
ibmcase/eda-store-simulator        "/deployments/run-ja…"    0.0.0.0:8080->8080/
rabbitmq:3-management              "docker-entrypoint.s…"    0.0.0.0:5672->5672/tcp, 15671/tcp, 15691-15692/tcp, 25672/tcp, 0.0.0.0:15672->15672/tcp   
strimzi/kafka:latest-kafka-2.6.0   "sh -c 'bin/zookeepe…"    0.0.0.0:2181->2181/                                                                                      
```

* Once the different containers are started, you can deploy the source connector as describe [in this section](#) but which come to a simple POST

```shell
curl -X POST -H "Content-Type: application/json" http://localhost:8083/connectors   --data "@./rabbitmq-source.json
```

* And then looking at the deployed connectors using [http://localhost:8083/connectors](http://localhost:8083/connectors) or the RabbitMQ connector with [http://localhost:8083/connectors/RabbitMQSourceConnector](http://localhost:8083/connectors/RabbitMQSourceConnector).

* Send some records using the simulator using the [http://localhost:8080/#/simulator](http://localhost:8080/#/simulator) URL and the user interface: 

 ![1](./images/store-simul-rmq.png)


* Verify the RabbitMQ settings

In a Web Browser go to [http://localhost:1567/](http://localhost:1567/) using the rabbit-user/rabbit-pass login.

You should reach this console:

![7](./images/rabbitmq-overview.png)

Go to the Queue tab and select the `items` queue:

![9](./images/rabbitmq-item-queue-2.png)

* Now verify the Kafka connect-* topics are created successfully:

 ```shell
 docker run -ti --network kafkanet strimzi/kafka:latest-kafka-2.6.0 bash -c "/opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka:9092 --list"
 # you should get at least
 __consumer_offsets
 connect-configs
 connect-offsets
 connect-status
 items
 ```

* Verify the message arrived to the `items` in kafka topic:

 ```shell
 docker run -ti --network kafkanet strimzi/kafka:latest-kafka-2.6.0 bash -c "/opt/kafka/bin/kafka-console-consumer.sh --bootstrap-server kafka:9092 --topic items --from-beginning"

 # You may have a trace like which maps the messages sent 
 "{\"id\":0,\"price\":11.0,\"quantity\":6,\"sku\":\"Item_5\",\"storeName\":\"Store_3\",\"timestamp\":\"2020-10-23T19:11:26.395325\",\"type\":\"SALE\"}"
"{\"id\":1,\"price\":68.5,\"quantity\":0,\"sku\":\"Item_5\",\"storeName\":\"Store_1\",\"timestamp\":\"2020-10-23T19:11:26.395447\",\"type\":\"SALE\"}"
 ```

You validated the solution work end to end. Now we can try to deploy those components to OpenShift.

## Deploy on OpenShift

In this section, we want to run and deploy the connector and Rabbit MQ on OpenShift using Event Streams on Premise.

### Pre-requisites

<InlineNotification kind="warning"><strong>TODO</strong></InlineNotification>

_Pull in necessary pre-req from the [Realtime Inventory Pre-reqs](/scenarios/realtime-inventory/#general-pre-requisites), like for example the deployment of the store simulator._

## Deploy Rabbit MQ

## Configure the kafka connector for Rabbitmq source

The `rabbitmq-source.json` define the connector and the RabbitMQ connection parameters:

```json
{
    "name": "RabbitMQSourceConnector",
    "config": {
        "connector.class": "com.ibm.eventstreams.connect.rabbitmqsource.RabbitMQSourceConnector",
        "tasks.max": "1",
        "kafka.topic" : "items",
        "rabbitmq.host": "rabbitmq",
        "rabbitmq.queue" : "items",
        "rabbitmq.prefetch.count" : "500",
        "rabbitmq.automatic.recovery.enabled" : "true",
        "rabbitmq.network.recovery.interval.ms" : "10000",
        "rabbitmq.topology.recovery.enabled" : "true"
    }
}
```

This file is uploaded to Kafka Connect via a PORT operation:

```shell
curl -X POST -H "Content-Type: application/json" http://localhost:8083/connectors   --data "@./rabbitmq-source.json"
```

To verify use: `curl -X GET http://localhost:8083/connectors`.

In Kafka connect trace you should see:

```shell
[Worker clientId=connect-1, groupId=eda-kconnect] Connector RabbitMQSourceConnector config updated
...
Starting connector RabbitMQSourceConnector
...
 Starting task RabbitMQSourceConnector-0

```

And Rabbitmq that get the connection from Kafka Connect.

```shell
rabbitmq_1  [info] <0.1766.0> accepting AMQP connection <0.1766.0> (172.19.0.3:33040 -> 172.19.0.2:5672)
kconnect_1  INFO Creating Channel (com.ibm.eventstreams.connect.rabbitmqsource.RabbitMQSourceTask:61)
rabbitmq_1  connection <0.1766.0> (172.19.0.3:33040 -> 172.19.0.2:5672): user 'rabbit-user' authenticated and granted access to vhost '/'
```

