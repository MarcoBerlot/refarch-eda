{"componentChunkName":"component---src-pages-journey-201-index-mdx","path":"/journey/201/","result":{"pageContext":{"frontmatter":{"title":"Learning Journey - deeper dive (201 content)","description":"Learning more about Event Streams, Event Driven Solution"},"relativePagePath":"/journey/201/index.mdx","titleType":"append","MdxNode":{"id":"3ec8f4f7-4b17-5788-a8d2-ffa407f4d88f","children":[],"parent":"a5966c9f-5f7d-5562-b8b2-d731afa5cdc3","internal":{"content":"---\ntitle: Learning Journey - deeper dive (201 content)\ndescription: Learning more about Event Streams, Event Driven Solution\n---\n\n<InlineNotification kind=\"warning\">\n<strong>Updated 10/13/2021 - Work In Progress</strong>\n</InlineNotification>\n\nIn this `201` content, you should be able to learn more about Kafka, Event Streams, Messaging, and Event-driven solution.\n\n<AnchorLinks>\n  <AnchorLink>More Kafka</AnchorLink>\n  <AnchorLink>Production deployment - High Availability</AnchorLink>\n  <AnchorLink>Performance considerations</AnchorLink>\n</AnchorLinks>\n\n\n## More Kafka\n\nWe have already covered the Kafka architecture in [this section](https://ibm-cloud-architecture.github.io/refarch-eda/technology/kafka-overview/#kafka-components).\nWhen we deploy Event Streams on Kubernetes, it uses Operator, and it is in fact a wrapper on top of [Strimzi](http://strimzi.io),\nthe open source kafka operator.\n\n### Strimzi\n\n[Strimzi](https://strimzi.io/) uses the Cluster Operator to deploy and manage Kafka (including Zookeeper) and Kafka Connect clusters. \nWhen the Strimzi Cluster Operator is up and runnning, it starts to watch for certain OpenShift or Kubernetes resources containing the \ndesired Kafka and/or Kafka Connect cluster configuration. \n\n![Strimzi](./images/strimzi.png)\n\nIt supports the following capabilities:\n\n* Deploy Kafka OOS on any OpenShift or k8s platform\n* Support TLS and SCRAM-SHA authentication, and automated certificate management\n* Define operators for cluster, users and topics\n* All resources are defined in yaml file so easily integrated into GitOps\n\nThe Cluster Operator is a pod used to deploys and manages Apache Kafka clusters, Kafka \nConnect, Kafka MirrorMaker (1 and 2), Kafka Bridge, Kafka Exporter, and the Entity Operator.\nWhen deployed the following commands goes to the Cluster operator:\n\n```shell\n# Get the current cluster list\noc get kafka\n# get the list of topic\noc get kafkatopics\n```\n\n#### Installation on OpenShift\n\nThe Strimzi operators deployment is done in two phases:\n\n* Deploy the main operator via Subscription\n* Deploy one to many instances of the Strimzi CRDs: cluster, users, topics...\n\nFor that we have define subscription and configuration in [this eda-gitops-catalog repo](https://github.com/ibm-cloud-architecture/eda-gitops-catalog). \nSo below are the operations to perform:\n\n```shell\n # clone \n git clone https://github.com/ibm-cloud-architecture/eda-gitops-catalog.git\n # Define subscription\n oc apply -k kafka-strimzi/operator/overlays/stable/\n # The subscription creates an operator pod under the openshift-operators project\n oc get pods -n openshift-operators\n # Create a project e.g. strimzi\n oc new-project strimzi\n # deploy a simple kafka cluster with 3 brokers\n oc apply -k  kafka-strimzi/instance/\n # Verify installation\n oc get pods\n # should get kafka, zookeeper and the entity operator running.\n```\n\nThe [Strimzi documentation](https://strimzi.io/docs/operators/latest/using.html) is very good to present a lot of configuration and tuning practices.\n\n#### Application\n\nAll applications written with Kafka API will work the same way with Strimzi and Event Streams. So developer\ncan use Strimzi images for their local development.\n\n## Production deployment - High Availability\n\nKafka clustering brings availability for message replication and failover, see details in this [high availability section.](/technology/kafka-overview/advance/#high-availability)\nThis chapter also presents replicas, in-synch replicas concepts and failure scenarios.\n\n## Performance considerations\n\n\n## Kafka Connect Framework\n\n## Integrate with MQ\n\n## Debezium change data capture\n\n\n## Schema registry\n\n## Anatomy of an event-driven microservice\n\n## AsyncAPI\n\n[This article on AsyncAPI management](/patterns/api-mgt/)\n\n## Mirroring Data\n\n\n## Deployment with GitOps practices\n\n","type":"Mdx","contentDigest":"61b38e365f796b4ec7a17c5b11c88643","owner":"gatsby-plugin-mdx","counter":794},"frontmatter":{"title":"Learning Journey - deeper dive (201 content)","description":"Learning more about Event Streams, Event Driven Solution"},"exports":{},"rawBody":"---\ntitle: Learning Journey - deeper dive (201 content)\ndescription: Learning more about Event Streams, Event Driven Solution\n---\n\n<InlineNotification kind=\"warning\">\n<strong>Updated 10/13/2021 - Work In Progress</strong>\n</InlineNotification>\n\nIn this `201` content, you should be able to learn more about Kafka, Event Streams, Messaging, and Event-driven solution.\n\n<AnchorLinks>\n  <AnchorLink>More Kafka</AnchorLink>\n  <AnchorLink>Production deployment - High Availability</AnchorLink>\n  <AnchorLink>Performance considerations</AnchorLink>\n</AnchorLinks>\n\n\n## More Kafka\n\nWe have already covered the Kafka architecture in [this section](https://ibm-cloud-architecture.github.io/refarch-eda/technology/kafka-overview/#kafka-components).\nWhen we deploy Event Streams on Kubernetes, it uses Operator, and it is in fact a wrapper on top of [Strimzi](http://strimzi.io),\nthe open source kafka operator.\n\n### Strimzi\n\n[Strimzi](https://strimzi.io/) uses the Cluster Operator to deploy and manage Kafka (including Zookeeper) and Kafka Connect clusters. \nWhen the Strimzi Cluster Operator is up and runnning, it starts to watch for certain OpenShift or Kubernetes resources containing the \ndesired Kafka and/or Kafka Connect cluster configuration. \n\n![Strimzi](./images/strimzi.png)\n\nIt supports the following capabilities:\n\n* Deploy Kafka OOS on any OpenShift or k8s platform\n* Support TLS and SCRAM-SHA authentication, and automated certificate management\n* Define operators for cluster, users and topics\n* All resources are defined in yaml file so easily integrated into GitOps\n\nThe Cluster Operator is a pod used to deploys and manages Apache Kafka clusters, Kafka \nConnect, Kafka MirrorMaker (1 and 2), Kafka Bridge, Kafka Exporter, and the Entity Operator.\nWhen deployed the following commands goes to the Cluster operator:\n\n```shell\n# Get the current cluster list\noc get kafka\n# get the list of topic\noc get kafkatopics\n```\n\n#### Installation on OpenShift\n\nThe Strimzi operators deployment is done in two phases:\n\n* Deploy the main operator via Subscription\n* Deploy one to many instances of the Strimzi CRDs: cluster, users, topics...\n\nFor that we have define subscription and configuration in [this eda-gitops-catalog repo](https://github.com/ibm-cloud-architecture/eda-gitops-catalog). \nSo below are the operations to perform:\n\n```shell\n # clone \n git clone https://github.com/ibm-cloud-architecture/eda-gitops-catalog.git\n # Define subscription\n oc apply -k kafka-strimzi/operator/overlays/stable/\n # The subscription creates an operator pod under the openshift-operators project\n oc get pods -n openshift-operators\n # Create a project e.g. strimzi\n oc new-project strimzi\n # deploy a simple kafka cluster with 3 brokers\n oc apply -k  kafka-strimzi/instance/\n # Verify installation\n oc get pods\n # should get kafka, zookeeper and the entity operator running.\n```\n\nThe [Strimzi documentation](https://strimzi.io/docs/operators/latest/using.html) is very good to present a lot of configuration and tuning practices.\n\n#### Application\n\nAll applications written with Kafka API will work the same way with Strimzi and Event Streams. So developer\ncan use Strimzi images for their local development.\n\n## Production deployment - High Availability\n\nKafka clustering brings availability for message replication and failover, see details in this [high availability section.](/technology/kafka-overview/advance/#high-availability)\nThis chapter also presents replicas, in-synch replicas concepts and failure scenarios.\n\n## Performance considerations\n\n\n## Kafka Connect Framework\n\n## Integrate with MQ\n\n## Debezium change data capture\n\n\n## Schema registry\n\n## Anatomy of an event-driven microservice\n\n## AsyncAPI\n\n[This article on AsyncAPI management](/patterns/api-mgt/)\n\n## Mirroring Data\n\n\n## Deployment with GitOps practices\n\n","fileAbsolutePath":"/home/runner/work/refarch-eda/refarch-eda/docs/src/pages/journey/201/index.mdx"}}},"staticQueryHashes":["1054721580","1054721580","1364590287","2102389209","2102389209","2456312558","2746626797","2746626797","3018647132","3018647132","3037994772","3037994772","768070550"]}